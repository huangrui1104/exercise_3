{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31m0.01s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "\u001b[1;31m0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "\u001b[1;31m0.00s - to python to disable frozen modules.\n",
      "\u001b[1;31m0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "\u001b[1;31mBad file descriptor (C:\\ci\\zeromq_1616055400030\\work\\src\\epoll.cpp:100). \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('gutenberg')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Read Moby Dick file from Gutenberg dataset\n",
    "moby_dick = gutenberg.raw('melville-moby_dick.txt')\n",
    "\n",
    "# Tokenization\n",
    "tokens = word_tokenize(moby_dick)\n",
    "\n",
    "# Stop-words filtering\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_tokens = [token for token in tokens if token.lower() not in stop_words]\n",
    "\n",
    "# Parts-of-Speech (POS) tagging\n",
    "pos_tags = nltk.pos_tag(filtered_tokens)\n",
    "\n",
    "# POS frequency\n",
    "pos_counts = FreqDist(tag for (word, tag) in pos_tags)\n",
    "top_pos = pos_counts.most_common(5)\n",
    "\n",
    "# Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_tokens = [lemmatizer.lemmatize(token, pos=tag[0].lower()) for token, tag in pos_tags[:20]]\n",
    "\n",
    "# Plotting frequency distribution\n",
    "pos_values = [count for tag, count in top_pos]\n",
    "pos_labels = [tag for tag, count in top_pos]\n",
    "\n",
    "plt.bar(pos_labels, pos_values)\n",
    "plt.xlabel('Parts of Speech')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('POS Frequency Distribution')\n",
    "plt.show()\n",
    "\n",
    "# Optional: Sentiment Analysis\n",
    "# Perform sentiment analysis on the Moby Dick text\n",
    "\n",
    "# Define positive and negative words\n",
    "positive_words = ['good', 'great', 'excellent']\n",
    "negative_words = ['bad', 'poor', 'terrible']\n",
    "\n",
    "# Calculate sentiment score\n",
    "sentiment_score = 0\n",
    "for word in filtered_tokens:\n",
    "    if word.lower() in positive_words:\n",
    "        sentiment_score += 1\n",
    "    elif word.lower() in negative_words:\n",
    "        sentiment_score -= 1\n",
    "\n",
    "# Calculate average sentiment score\n",
    "average_sentiment_score = sentiment_score / len(filtered_tokens)\n",
    "\n",
    "# Determine overall text sentiment\n",
    "if average_sentiment_score > 0.05:\n",
    "    overall_sentiment = 'positive'\n",
    "else:\n",
    "    overall_sentiment = 'negative'\n",
    "\n",
    "# Display sentiment analysis results\n",
    "print(f\"Average Sentiment Score: {average_sentiment_score}\")\n",
    "print(f\"Overall Text Sentiment: {overall_sentiment}\")\n",
    "\n",
    "# Commit your exercise solution to your GitHub account and provide the URL in the submission box"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
